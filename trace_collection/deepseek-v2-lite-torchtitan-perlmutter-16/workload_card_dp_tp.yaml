# workload_card_dp_tp.yaml - DeepSeek-V2-Lite DP+TP Configuration
version: 1

description: >
  DeepSeek-V2-Lite (16B MoE) training on 8 GPUs with DP + TP parallelism.
  2 Perlmutter GPU nodes (2 nodes Ã— 4 GPUs = 8 GPUs total).
  Configuration: dp_replicate=2, dp_shard=2, tp=2
  (2 DP-replicate groups, each with shard degree 2 and 2-way TP).
  MoE model with expert parallelism potential; all-reduce for TP and DP/FSDP.
  TorchTitan framework with NCCL; uses all-reduce for TP and gradient sync for DP/FSDP.

hf_url: https://huggingface.co/deepseek-ai/DeepSeek-V2-Lite
trace_url:  # TODO: Add Google Drive link after uploading traces

workload:
  model:
    phase: training
    moe: true
    granularity: model_fwd_bwd_pass
    model_family: deepseek_v2_lite
    precision: bf16
    epochs: 1
    iteration: 5
  data:
    batch_size: 4
    seq_len: 8192
    dataset: c4
  hardware:
    network_topo:
      topology: slingshot
      bandwidth_gbps:
        - 200   # Scale-out: 200 Gbps per NIC over Slingshot (inter-node)
        - 2000  # Scale-up: Approx NVLink/NVSwitch aggregate bandwidth (Gbps)
    xpu_spec:
      type: GPU
      model: nvidia_a100
      total_count: 8
      count_per_node: 4
    driver_version: cuda_12.4

Model-executor:
  framework:
    name: torchtitan
    compiler_tool_selection: plain_pytorch
  model_plan_parallelization:
    dp_replicate: 2
    dp_shard: 2
    tp: 2
    pp: 1
    cp: 1
  communication_library:
    name: NCCL
    version: 2.18.5
    env:
      NCCL_IB_QPS_PER_CONNECTION: "4"
      NCCL_DEBUG: INFO
  protocol_selection:
    - rocev2  # Scale-out over Slingshot (inter-node DP gradient sync)
    - p2p     # Intra-node GPUDirect/NVLink (TP communication)

metric_source:
  traces:
    - nsys
    - torch_et
    - kineto_trace
  metrics_specific_trace:
    - nvtx_ranges
    - moe_routing  # Expert token assignment logging
